{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Medical Image Segmentation using DIGITS\n",
    "\n",
    "Medical professionals commonly use cardiac MRIs to help diagnose various heart conditions such as hypertrophy (enlargement and thickening of the left ventricle walls), heart failure with myocardial infarction (heart attack) and heart failure without myocardial infarction.  The process of reviewing MRIs is time consuming – time that either the patient or the doctor may not have.  One of the more common deep learning computer vision tasks – image segmentation – can be applied to cardiac MRIs to assist doctors in quickly and automatically locating the area of the left ventricle for faster diagnosis.\n",
    "\n",
    "In this lab, we will be using NVIDIA DIGITS to architect, train and validate a neural network that learns to locate the left ventricle in cardiac MRIs.  We will be using the 2009 Cardiac MR Left Ventricle Segmentation Challenge dataset. The dataset consists of 16-bit MRI images in DICOM format and expert-drawn contours in text format (coordinates of contour polylines).  This dataset was originally published with the following paper:\n",
    "\n",
    "Radau P, Lu Y, Connelly K, Paul G, Dick AJ, Wright GA. “Evaluation Framework for Algorithms Segmenting Short Axis Cardiac MRI.” The MIDAS Journal – Cardiac MR Left Ventricle Segmentation Challenge, http://hdl.handle.net/10380/3070\n",
    "\n",
    "## Process\n",
    "The approach we take in this lab is as follows:\n",
    "\n",
    "•\tAnnounce the Sunnybrook cardiac images dataset to DIGITS and have DIGITS create training and validation files automatically;\n",
    "<br>\n",
    "•\tUse a custom network based on AlexNet architecture to train a model;\n",
    "<br>\n",
    "•\tValidate the new model;\n",
    "<br>\n",
    "•\tModify the existing model by introducing the Dice Metric;\n",
    "<br>\n",
    "•\tUtilize transfer learning to further improve results;\n",
    "<br>\n",
    "•\tCreate an additional model that performs finer grain image segmentation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Creating the dataset in DIGITS\n",
    "\n",
    "[Click here](/digits/) to open DIGITS.  \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Any time you need to return to the DIGITS home page simply click on DIGITS found in the upper left corner as shown in the screenshot below:\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![digits](Digits.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "We will be using a custom plug-in to load the data into DIGITS.\n",
    "DIGITS plug-ins are thin layers that users can implement to load data that are not in a format that DIGITS natively supports.\n",
    "Plug-ins define a list of options to present to the user as part of the data creation form.\n",
    "Plug-ins also take care of loading the data in Python into a format that DIGITS understands: the ubiquitous `numpy.array` object.\n",
    "See for example the code for the [Image Segmentation plug-in](https://github.com/NVIDIA/DIGITS/tree/278d24b108c5c195ca3d07da82490e187012a2d4/digits/extensions/data/imageSegmentation).\n",
    "\n",
    "The `Sunnybrook` plug-in reads 16-bit images from DICOM files (those images are the input of the network we will train) and creates black-and-white images out of the .txt files that delineate the contours of the left ventricle (those black-end-white images will be our labels).\n",
    "\n",
    "On the home page, click `Datasets > New Dataset > Images > Sunnybrook LV Segmentation`.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "![create_dataset](Create_Dataset.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "In the dataset creation form:\n",
    "- set `image folder` to: **/data/challenge_training**\n",
    "- set `contour folder` to: **/data/Sunnybrook Cardiac MR Database ContoursPart3**\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![image_contour](Image_Contour.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- set `feature encoding` to `none`\n",
    "- set `encoder batch size` to `1`\n",
    "- set `dataset name` to `Sunnybrook`\n",
    "- click `Create`.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![encoding_create](Encoding_Create.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "When the dataset is created you can refresh the page to review the data shapes:\n",
    "- features (MRI images) are 256x256 16-bit images\n",
    "- labels (contour images) are 256x256 black-and-white images\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![dataset_details](Dataset_Details.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "A sample feature/label pair may look like:\n",
    "<br>\n",
    "<br>\n",
    "![feature](img.png)\n",
    "<br>\n",
    "<br>\n",
    "![label](label.png)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "## Creating a model\n",
    "\n",
    "We will use a model from the FCN family.\n",
    "These models were first introduced in the following paper:\n",
    "\n",
    "> [Fully Convolutional Models for Semantic Segmentation](https://arxiv.org/abs/1411.4038)\n",
    "> Jonathan Long*, Evan Shelhamer*, Trevor Darrell\n",
    "> CVPR 2015\n",
    "> arXiv:1411.4038\n",
    "<br>\n",
    "\n",
    "The first model we will create is the simplest model from this family of models.\n",
    "It is derived from the popular AlexNet model.\n",
    "\n",
    "> NOTE: AlexNet is a classification network but with a few minor modifications it can be converted into a segmentation network.\n",
    "> See the above paper for more details.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "On the DIGITS home page (click DIGITS in the top left corner), click `New Model > Images > Sunnybrook LV Segmentation`.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![create_model](Create_Model.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "In the model creation form:\n",
    "- set the number of epochs to `5`\n",
    "- set the snapshot interval to `5`\n",
    "- select the `Sunnybrook` dataset\n",
    "- set the base learning rate to `1e-4`\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![epochs_lr](Epochs_LR.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- click the `custom network` tab then paste this [net description](/nKQrP6kVL9JX/edit/fcn-alexnet.protobuf)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![custom_network](Custom_Network.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- name your model `fcn_alexnet-sunnybrook`\n",
    "- click `Create`\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![model_create](Model_Create.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "You should see that after a few epochs the network has learnt to predict the location of the left ventricle with over 98% accuracy.\n",
    "This means that 98% of pixels are correctly predicted as belonging to either the left ventricle or the background.\n",
    "This seems very good!\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![accuracy_task1](Accuracy_Task1.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Now let us test the model on an image from the validation set.\n",
    "Scroll down to the model page and select `Image Segmentation` in `Visualization Method`.\n",
    "In `Test a record from validation set` select `SC-HF-NI-3`.\n",
    "Check `Show visualizations and statistics`.\n",
    "Click `Test`.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![trainedmodel_task1](TrainedModel_Task1.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "A new page opens up.\n",
    "There you can see how the image was segmented.\n",
    "Can you spot the location of the left ventricle? \n",
    "\n",
    "Oh no! The segmented image is simply showing the original image! The network didn't find a single pixel of the left ventricle!\n",
    "How is that possible? \n",
    "\n",
    "It turns out that in this dataset, less than 2% of pixels represent the left ventricle. The network has just lazily learnt to classify everything as background.\n",
    "\n",
    "This is a typical \"class imbalance\" problem.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![trainedmodel_task1_result](Validation.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "## Dice metric\n",
    "\n",
    "We need a better metric to evaluate the performance of the model.\n",
    "A popular metric for this kind of problems is the [Dice coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient).\n",
    "\n",
    "Let us add this metric to our model.\n",
    "By default, Caffe, the underlying Deep Learning framework we are using, does not support this metric.\n",
    "However this is easily added through a custom Python layer.\n",
    "\n",
    "DIGITS makes it easy to define and upload a custom layer. Save this [custom layer](layers.py) as \"layers.py\" and review the code. You'll upload it to DIGITS soon.\n",
    "\n",
    "Now use the `Clone` button on the model that you just trained to create a new model with the same settings.\n",
    "In the custom network description, scroll down to the end and un-comment the `dice` each line *below* the title \"Dice Coefficient.\"\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![uncomment_dice](Uncomment_Dice.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "In the 'Python layers' menu, check `client-side file` then upload `layers.py`.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![python_layers](Python_Layers.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Name your model `fcn_alexnet-sunnybrook-with_dice`.\n",
    "Now click `Create`.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![model_create_dice](Model_Create_Dice.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "You will see that even though the accuracy is very high, the Dice coefficient remains at zero.\n",
    "Our model did not learn anything useful but at least we now have a metric to figure that out.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![dice_result](Dice_Result.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Transfer learning\n",
    "\n",
    "Part of the reason why we are unable to learn anything is that our dataset is too small for our model.\n",
    "We would need more samples.\n",
    "An alternative is to do \"transfer learning.\" I.E. Re-use knowledge that the model has acquired when training on another dataset and apply that knowledge to a different task.\n",
    "Here we will use a pre-trained Alexnet model that was trained on the 1.2M ImageNet database (ILSVRC2012).\n",
    "\n",
    "In order to be able to use the pre-trained Alexnet model, we need to make a modification to our dataset.  The Sunnybrook dataset is currently in grayscale; however, the pre-trained model is expecting three channels - RGB.  DIGITS provides an easy way to make this change.  \n",
    "\n",
    "Go to your datasets page and clone the Sunnybrook dataset. Change Channel Conversion setting from Grayscale to RGB as shown below. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![channel_conversion](Channel_Conversion.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Name the new copy Sunnybrook-RGB and click create.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Clone the last model you trained.\n",
    "Select the new Sunnybrook-RGB dataset and set the number of epochs to `20`.\n",
    "\n",
    "Remember to re-upload your Python layer.\n",
    "\n",
    "Check the box `Show advanced learning rate options` and set the learning rate policy to `fixed`.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![advanced_lr](Advanced_LR.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "In `pretrained model` point DIGITS to this path: `/data/fcn_alexnet.caffemodel`.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![pretrained_model](Pretrained_Model.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Name your model `fcn_alexnet-sunnybrook-with_dice-pretrained`.\n",
    "Now click `Create`.  \n",
    "\n",
    "NOTE: This will likely take around 10 minutes to complete.\n",
    "\n",
    "\n",
    "After training you will see that the Dice coefficient exceeds 65%.\n",
    "<br>\n",
    "<br>\n",
    "![pretrained_model2](Pretrained_Model2.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Now test the same image again.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![pretrained_results2](Pretrained_Results2.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "You will notice a greyish / white blob on the image which corresponds to the network's prediction of the location of the left ventricle.\n",
    "As you can see, the edges are pretty rough.\n",
    "This is because the predictions in FCN-Alexnet are made at a 32-pixel stride, meaning that only one prediction is made for each block of 32x32 pixels.\n",
    "This is too coarse.\n",
    "\n",
    "## FCN-8s\n",
    "\n",
    "We will now use a finer model called FCN-8s.  This model is able to make predictions at a much finer grain - down to 8x8 blocks.\n",
    "Clone the model you just trained.  Remember to re-upload your custom Python layer.  Set the batch size to `1` to reduce the memory footprint during training and set the number of epochs to 3.  NOTE: Time constraints warrant the use of 3 epochs; however, in practice you would likely specify a higher epoch value.  The screen captures that follow show the results when the number of epochs is 20 (so that a comparison can be made with the AlexNet example from the previous step).\n",
    "\n",
    "In the custom network tab paste the content of [`fcn-8s.protobuf`](/nKQrP6kVL9JX/edit/fcn-8s.protobuf).  In `pretrained model` point DIGITS to this path: `/data/fcn8s-heavy-pascal.caffemodel`.  Name your model `fcn_8s-sunnybrook-with_dice-pretrained`.\n",
    "\n",
    "\n",
    "After training you should see that the model reaches a Dice coefficient of over 88%.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![fcn8_model](FCN8_Model.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Now test the same image again, you should see that the contour of the prediction is much smoother.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![fcn8_validation](FCN8_Validation.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "## REFERENCE:  FCN-Alexnet and FCN-8s network descriptions\n",
    "\n",
    "* [`fcn-alexnet.protobuf`](/nKQrP6kVL9JX/edit/fcn-alexnet.protobuf)\n",
    "* [`fcn-8s.protobuf`](/nKQrP6kVL9JX/edit/fcn-8s.protobuf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
